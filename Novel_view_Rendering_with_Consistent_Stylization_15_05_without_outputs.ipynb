{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqmT68wdySBM"
      },
      "source": [
        "# **Novel-view Rendering with Consistent Stylization**\n",
        "<br />\n",
        "\n",
        "### Submitted by *Shirin Alanova* \n",
        "student of group 193, 4th year of study\n",
        " \n",
        "\n",
        "<br />\n",
        "\n",
        "### Approved by Supervisor: *Artem Filatov*\n",
        "Computer vision engineer\n",
        "\n",
        "<br />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-1wAHNIySBT"
      },
      "source": [
        "## Importing the required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whkj1CvFySBT"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "!wget https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n",
        "from plot_image_grid import image_grid\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR2Oft1WHq1n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith((\"1.13.\", \"2.0.\")) and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !pip install -v -v -v  'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flDOEaMvHtql"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from pytorch3d.io import load_objs_as_meshes, load_obj\n",
        "\n",
        "# Data structures and functions for rendering\n",
        "from pytorch3d.structures import Meshes\n",
        "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n",
        "from pytorch3d.vis.texture_vis import texturesuv_image_matplotlib\n",
        "from pytorch3d.renderer import (\n",
        "    look_at_view_transform,\n",
        "    FoVPerspectiveCameras, \n",
        "    PointLights, \n",
        "    DirectionalLights, \n",
        "    Materials, \n",
        "    RasterizationSettings, \n",
        "    MeshRenderer, \n",
        "    MeshRasterizer,  \n",
        "    SoftPhongShader,\n",
        "    Textures,\n",
        "    TexturesUV,\n",
        "    TexturesVertex,\n",
        "    TexturesAtlas,\n",
        "    HardPhongShader\n",
        ")\n",
        "\n",
        "from pytorch3d.renderer import (\n",
        "    BlendParams,\n",
        ")\n",
        "from pytorch3d.renderer.blending import hard_rgb_blend\n",
        "from pytorch3d.renderer.mesh import rasterizer\n",
        "\n",
        "# add path for demo utils functions \n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath(''))\n",
        "import pytorch3d\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torch.autograd.grad_mode import no_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFz7KiabGvWm"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgSS-u1_vJ6O"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/diploma_svg/\"\n",
        "save_folder = \"intro_\"\n",
        "svg_idx = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG3MlnI4Gk6y"
      },
      "source": [
        "Import mesh \"Cow\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNUzpjnIHval"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data/cow_mesh\n",
        "!wget -P data/cow_mesh https://dl.fbaipublicfiles.com/pytorch3d/data/cow_mesh/cow.obj\n",
        "!wget -P data/cow_mesh https://dl.fbaipublicfiles.com/pytorch3d/data/cow_mesh/cow.mtl\n",
        "!wget -P data/cow_mesh https://dl.fbaipublicfiles.com/pytorch3d/data/cow_mesh/cow_texture.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFMcQNJH69W"
      },
      "source": [
        "Let's create main functions and needed objects for creating mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5XrkhR-HP4N"
      },
      "outputs": [],
      "source": [
        "class SimpleShader(torch.nn.Module):\n",
        "    def __init__(self, device=\"cpu\", blend_params=None):\n",
        "        super().__init__()\n",
        "        self.blend_params = blend_params if blend_params is not None else BlendParams()\n",
        "\n",
        "    def forward(self, fragments, meshes, **kwargs) -> torch.Tensor:\n",
        "        blend_params = kwargs.get(\"blend_params\", self.blend_params)\n",
        "        texels = meshes.sample_textures(fragments)\n",
        "        images = hard_rgb_blend(\n",
        "            texels, fragments, blend_params\n",
        "        )  # change with some soft blending to recieve a better occlusion gradients\n",
        "        return images  # (N, H, W, 3) RGBA image\n",
        "\n",
        "\n",
        "def image_loader(image):\n",
        "    loader=transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])\n",
        "    image=Variable(loader(image), requires_grad=True).unsqueeze(0)    \n",
        "    return image.to(device, torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8av9djx2H91c"
      },
      "outputs": [],
      "source": [
        "R, T = look_at_view_transform(dist=2.7, elev=10, azim=-150)\n",
        "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "\n",
        "raster_settings = RasterizationSettings(\n",
        "    image_size=1024, \n",
        "    blur_radius=0.0, \n",
        ")\n",
        "\n",
        "\n",
        "renderer = MeshRenderer(\n",
        "    rasterizer=MeshRasterizer(\n",
        "        cameras=cameras, \n",
        "        raster_settings=raster_settings\n",
        "    ),\n",
        "    shader=SimpleShader(\n",
        "        device=device, \n",
        "    )\n",
        ")\n",
        "\n",
        "verts, faces_idx, aux = load_obj(\"/content/data/cow_mesh/cow.obj\")\n",
        "verts_uvs=[aux.verts_uvs.to(device)]\n",
        "faces = [faces_idx.verts_idx.to(device)]\n",
        "faces_uvs = [faces_idx.textures_idx.to(device)]\n",
        "texture_image = image_loader(Image.open('/content/data/cow_mesh/cow_texture.png')).permute(0, 2, 3, 1).to(device)\n",
        "texture = Textures(maps=texture_image, faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "mesh = Meshes(\n",
        "    verts=[verts.to(device)],   \n",
        "    faces=faces, \n",
        "    textures=texture\n",
        ")\n",
        "\n",
        "images = renderer(mesh, cameras=cameras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2HSabV4Hp1o"
      },
      "source": [
        "Let's watch a sample of rendered image and example of style image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP2S1TUYIHQk"
      },
      "outputs": [],
      "source": [
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2cU4fSLIqAj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"Texture\")\n",
        "plt.imshow(original_image.permute(0, 2, 3, 1).squeeze(0).cpu().detach().numpy())\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(save_path + save_folder + f\"graph_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "svg_idx += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuIual0qyhg3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.title(\"Texture with UV vertices\")\n",
        "texturesuv_image_matplotlib(mesh.textures, subsample=None)\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(save_path + save_folder + f\"graph_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "svg_idx += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70-2FImcIsU3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"Rendered image\")\n",
        "plt.imshow(images[0, ..., :3].cpu().detach().numpy())\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(save_path + save_folder + f\"graph_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "svg_idx += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-XCRz6CIums"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"Style image\")\n",
        "plt.imshow(style_image.permute(0, 2, 3, 1).squeeze(0).cpu().detach().numpy())\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(save_path + save_folder + f\"graph_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "svg_idx += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBwlTBF_ySBX"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pviznFwTIWwB"
      },
      "outputs": [],
      "source": [
        "model=models.vgg19(pretrained=True).features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHYXh075MTCo"
      },
      "source": [
        "Additionally, VGG networks are trained on images with each channel normalized by mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225]. We will use them to normalize the image before sending it into the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDbWvi_lySBZ"
      },
      "outputs": [],
      "source": [
        "#[0,5,10,19,28] are the index of the layers we will be using to calculate the loss as per the paper of NST\n",
        "#Defining a class that for the model\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG, self).__init__()\n",
        "        #Here we will use the following layers and make an array of their indices\n",
        "        # 0: block1_conv1\n",
        "        # 5: block2_conv1\n",
        "        # 10: block3_conv1\n",
        "        # 19: block4_conv1\n",
        "        # 28: block5_conv1\n",
        "        self.req_features= ['0', '5', '10', '19', '28'] \n",
        "        #Since we need only the 5 layers in the model so we will be dropping all the rest layers from the features of the model\n",
        "        self.model = models.vgg19(pretrained=True).features[:29] #model will contain the first 29 layers\n",
        "    \n",
        "   \n",
        "    #x holds the input tensor(image) that will be feeded to each layer\n",
        "    def forward(self, x):\n",
        "        #initialize an array that wil hold the activations from the chosen layers\n",
        "        features = []\n",
        "        #Iterate over all the layers of the mode\n",
        "        for layer_num, layer in enumerate(self.model):\n",
        "            #activation of the layer will stored in x\n",
        "            x = layer(x)\n",
        "            #appending the activation of the selected layers and return the feature array\n",
        "            if (str(layer_num) in self.req_features):\n",
        "                features.append(x)\n",
        "                \n",
        "        return features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0zyQ7T4ySBZ"
      },
      "source": [
        "## Defining the Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9rvHK5iySBZ"
      },
      "outputs": [],
      "source": [
        "def calc_content_loss(gen_feat,orig_feat):\n",
        "    #calculating the content loss of each layer by calculating the MSE between the content and generated features and adding it to content loss\n",
        "    content_l = torch.mean((gen_feat - orig_feat) ** 2) \n",
        "    return content_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH23g6fZySBZ"
      },
      "outputs": [],
      "source": [
        "def calc_style_loss(gen,style):\n",
        "    #Calculating the gram matrix for the style and the generated image\n",
        "    batch_size, channel, height, width = gen.shape\n",
        "\n",
        "    G = torch.mm(gen.view(channel, height * width), gen.view(channel, height * width).t())\n",
        "    A = torch.mm(style.view(channel, height * width), style.view(channel, height * width).t())\n",
        "        \n",
        "    #Calcultating the style loss of each layer by calculating the MSE between the gram matrix of the style image and the generated image and adding it to style loss\n",
        "    style_l = torch.mean((G - A) ** 2) #/(4*channel*(height*width)**2)\n",
        "    return style_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5LcNjIxU9bB"
      },
      "outputs": [],
      "source": [
        "def gaussian_pyramid_features(model, img, levels, type='none', cameras=None):    \n",
        "    pyramid_features = []\n",
        "    sizes = [784, 608, 432, 256]\n",
        "    if type == 'generate':\n",
        "        for i in range(levels):\n",
        "            texture = TexturesUV(maps=img.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "            mesh = Meshes(\n",
        "                verts=[verts.to(device)],   \n",
        "                faces=faces, \n",
        "                textures=texture\n",
        "            )\n",
        "            img_size = sizes[i]\n",
        "            rendered_img = renderer(mesh, cameras=cameras, raster_settings=RasterizationSettings(image_size=img_size, blur_radius=0.0))\n",
        "            target_feature = model(rendered_img[..., :3].permute(0, 3, 1, 2))\n",
        "            pyramid_features.append(target_feature)\n",
        "      
        "    else:\n",
        "        for i in range(levels):\n",
        "            img = transforms.Compose([transforms.Resize(sizes[i])])(img)\n",
        "            target_feature = model(img)\n",
        "            pyramid_features.append(target_feature)\n",
        "    return pyramid_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHzK3FNaW7s-"
      },
      "outputs": [],
      "source": [
        "def calculate_loss(model, gen_img, cameras, orig_img, style_img, content_weight, style_weight):\n",
        "    content_pyramid_features = gaussian_pyramid_features(model, orig_img, 4)\n",
        "    style_pyramid_features = gaussian_pyramid_features(model, style_img, 4)\n",
        "\n",
        "    gen_pyramid_features = gaussian_pyramid_features(model, gen_img, 4, type='generate', cameras=cameras)\n",
        "    \n",
        "    style_loss=0\n",
        "    content_loss=0\n",
        "    for gen_f, cont_f, style_f in zip(gen_pyramid_features, content_pyramid_features, style_pyramid_features):\n",
        "        for gen, cont, style in zip(gen_f, cont_f, style_f):\n",
        "            #extracting the dimensions from the generated image\n",
        "            content_loss += calc_content_loss(gen, cont)\n",
        "            style_loss += calc_style_loss(gen, style)\n",
        "    \n",
        "    #calculating the total loss of e th epoch\n",
        "    total_loss = content_weight * content_loss + style_weight * style_loss \n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4nenBf0ySBa"
      },
      "outputs": [],
      "source": [
        "#Load the model to the GPU\n",
        "model = VGG().to(device).eval() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1ajvNJy3mWB"
      },
      "outputs": [],
      "source": [
        "def plot_1(save_folder, gen_image):\n",
        "    global svg_idx\n",
        "    texture = TexturesUV(maps=gen_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "    mesh = Meshes(\n",
        "        verts=[verts.to(device)],   \n",
        "        faces=faces, \n",
        "        textures=texture\n",
        "    )\n",
        "    with no_grad():\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        x = renderer(mesh)\n",
        "        plt.imshow(x[0].cpu().numpy()[..., :3])\n",
        "        plt.axis(\"off\")\n",
        "        plt.savefig(save_path + save_folder + f\"graph_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "        svg_idx += 1\n",
        "        plt.show()\n",
        "        \n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(gen_image.detach().cpu()[0].permute(1, 2, 0).numpy())\n",
        "    plt.savefig(save_path + save_folder + f\"graph_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "    svg_idx += 1\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBLOjSBg3yKu"
      },
      "outputs": [],
      "source": [
        "def plot_2(save_folder, gen_img, count=12, rows=3, cols=4):\n",
        "    global svg_idx\n",
        "    texture = TexturesUV(maps=gen_img.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "    mesh = Meshes(\n",
        "        verts=[verts.to(device)],   \n",
        "        faces=faces, \n",
        "        textures=texture\n",
        "    )\n",
        "\n",
        "    meshes = mesh.extend(count)\n",
        "    elev = torch.linspace(0, 180, count)\n",
        "    azim = torch.linspace(-180, 180, count)\n",
        "\n",
        "    R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "    cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "\n",
        "    logger = logging.getLogger()\n",
        "    old_level = logger.level\n",
        "    logger.setLevel(100)\n",
        "\n",
        "    with no_grad():\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        x = renderer(meshes, cameras=cameras)\n",
        "        image_grid(x.cpu().numpy(), rows=rows, cols=cols, rgb=True)\n",
        "        plt.savefig(save_path + save_folder + f\"graph_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "        svg_idx += 1\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UOgNozA5JcJ"
      },
      "outputs": [],
      "source": [
        "def plot_3(save_folder, history):\n",
        "    global svg_idx\n",
        "    history = np.array(history)\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(\"Total loss history\")\n",
        "    plt.xlabel(\"iteration\")\n",
        "    plt.plot(history)\n",
        "    plt.savefig(save_path + save_folder + f\"graph_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "    svg_idx += 1\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7mpVspeNUMM"
      },
      "source": [
        "## Experiment № 1 - Camera rotation strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML0UrlgrySBa"
      },
      "source": [
        "### A fixed camera position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1SsFRX6ySBb"
      },
      "outputs": [],
      "source": [
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "save_folder = \"res_1_one_cam_\"\n",
        "\n",
        "epoch=100\n",
        "lr=0.05\n",
        "content_weight=5\n",
        "style_weight = 100\n",
        "\n",
        "R, T = look_at_view_transform(dist=2.7, elev=10, azim=-150)\n",
        "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "\n",
        "model=VGG().to(device).eval() \n",
        "optimizer=optim.Adam([generated_image],lr=lr)\n",
        "history = []\n",
        "print('Optimizing..')\n",
        "for e in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total_loss=calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "    \n",
        "    total_loss.backward()\n",
        "    history.append(total_loss.detach().cpu().numpy())\n",
        "    optimizer.step()\n",
        "    \n",
        "    #print the image and save it after each 100 epoch\n",
        "    if(not (e%30)):\n",
        "        print(\"Iteration\", e)\n",
        "        print(\"Total Loss:\", total_loss.item())\n",
        "        save_image(generated_image,\"gen.png\")\n",
        "        if len(history) > 1:\n",
        "            plt.plot(np.array(history))\n",
        "            plt.show()\n",
        "        img = mpimg.imread('gen.png')\n",
        "        imgplot = plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvfadf0tNSoH"
      },
      "outputs": [],
      "source": [
        "plot_1(save_folder, generated_image)\n",
        "plot_2(save_folder, generated_image)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMouI1DeVIe0"
      },
      "source": [
        "### Rotation about a single principal axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRi06VxHU9ec"
      },
      "outputs": [],
      "source": [
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "save_folder = \"res_1_seq_cam_\"\n",
        "\n",
        "epoch=100\n",
        "lr=0.05\n",
        "content_weight = 5\n",
        "style_weight = 100\n",
        "azims = torch.linspace(0, 360, epoch)\n",
        "\n",
        "model=VGG().to(device).eval() \n",
        "optimizer=optim.Adam([generated_image],lr=lr)\n",
        "history = []\n",
        "print('Optimizing..')\n",
        "for e in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    elev = 0\n",
        "    azim = azims[e]\n",
        "    R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "    cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "    texture = TexturesUV(maps=generated_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "    mesh = Meshes(\n",
        "        verts=[verts.to(device)],   \n",
        "        faces=faces, \n",
        "        textures=texture\n",
        "    )\n",
        "    images = renderer(mesh, cameras=cameras)[..., :3].permute(0, 3, 1, 2)\n",
        "    \n",
        "    \n",
        "    total_loss=calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "    \n",
        "    total_loss.backward()\n",
        "    history.append(total_loss.detach().cpu().numpy())\n",
        "    optimizer.step()\n",
        "    \n",
        "    #print the image and save it after each 100 epoch\n",
        "    if(not (e%1)):\n",
        "        print(\"Iteration\", e)\n",
        "        print(\"Total Loss:\", total_loss.item())\n",
        "        save_image(generated_image,\"gen.png\")\n",
        "        if len(history) > 1:\n",
        "            plt.plot(np.array(history))\n",
        "            plt.show()\n",
        "        with no_grad():\n",
        "                plt.figure(figsize=(5, 8))\n",
        "                plt.imshow(images.permute(0, 2, 3, 1)[0].cpu().numpy()[..., :3])\n",
        "                plt.show()\n",
        "        img = mpimg.imread('gen.png')\n",
        "        imgplot = plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgHjVbl2XrCf"
      },
      "outputs": [],
      "source": [
        "plot_1(save_folder, generated_image)\n",
        "plot_2(save_folder, generated_image)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnfwmk21S9jk"
      },
      "source": [
        "### Effect of parameters number of iterations, content and style weights on stylization process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdrBKICNIa1h"
      },
      "outputs": [],
      "source": [
        "#generated_image=original_image.clone().requires_grad_(True)\n",
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "\n",
        "def train(epoch, lr, content_weight, style_weight):\n",
        "\n",
        "    generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "    azims = torch.linspace(0, 360, epoch)\n",
        "\n",
        "    model=VGG().to(device).eval() \n",
        "    optimizer=optim.Adam([generated_image], lr=lr)\n",
        "    history = []\n",
        "    print('Optimizing..')\n",
        "    for e in range(epoch):\n",
        "        optimizer.zero_grad()\n",
        "        elev = 0\n",
        "        azim = azims[e]\n",
        "        R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "        cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "        texture = TexturesUV(maps=generated_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "        mesh = Meshes(\n",
        "            verts=[verts.to(device)],   \n",
        "            faces=faces, \n",
        "            textures=texture\n",
        "        )\n",
        "        images = renderer(mesh, cameras=cameras)[..., :3].permute(0, 3, 1, 2)\n",
        "        \n",
        "        \n",
        "        total_loss = calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "        \n",
        "        total_loss.backward()\n",
        "        history.append(total_loss.detach().cpu().numpy())\n",
        "        optimizer.step()\n",
        "        \n",
        "        #print the image and save it after each 100 epoch\n",
        "        if(not (e%10)):\n",
        "            print(\"Iteration\", e)\n",
        "            print(\"Total Loss:\", total_loss.item())\n",
        "            save_image(generated_image,\"gen.png\")\n",
        "            if len(history) > 1:\n",
        "                plt.plot(np.array(history))\n",
        "                plt.show()\n",
        "            with no_grad():\n",
        "                    plt.figure(figsize=(5, 8))\n",
        "                    plt.imshow(images.permute(0, 2, 3, 1)[0].cpu().numpy()[..., :3])\n",
        "                    plt.show()\n",
        "            img = mpimg.imread('gen.png')\n",
        "            imgplot = plt.imshow(img)\n",
        "            plt.show()\n",
        "    return generated_image, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT2Ec9q8TVHY"
      },
      "source": [
        "#### Number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj_G7K0pIa_w"
      },
      "outputs": [],
      "source": [
        "save_folder = \"res_1_exp_1_\"\n",
        "gen_img, history = train(epoch=10,\n",
        "                        lr=0.05,\n",
        "                        content_weight=5,\n",
        "                        style_weight=100)\n",
        "\n",
        "plot_1(save_folder, gen_img)\n",
        "plot_2(save_folder, gen_img)\n",
        "plot_3(save_folder, history)\n",
        "\n",
        "gen_img, history = train(epoch=200,\n",
        "                        lr=0.05,\n",
        "                        content_weight=5,\n",
        "                        style_weight=100)\n",
        "\n",
        "plot_1(save_folder, gen_img)\n",
        "plot_2(save_folder, gen_img)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvEB-1liTL-H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGtJMPCjTcDz"
      },
      "source": [
        "#### Content weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1n_5kEBdvoa"
      },
      "outputs": [],
      "source": [
        "save_folder = \"res_1_exp_2_\"\n",
        "gen_img, history = train(epoch=100,\n",
        "                        lr=0.05,\n",
        "                        content_weight=1,\n",
        "                        style_weight=100)\n",
        "\n",
        "plot_1(save_folder, gen_img)\n",
        "plot_2(save_folder, gen_img)\n",
        "plot_3(save_folder, history)\n",
        "\n",
        "gen_img, history = train(epoch=100,\n",
        "                        lr=0.05,\n",
        "                        content_weight=20,\n",
        "                        style_weight=100)\n",
        "\n",
        "plot_1(save_folder, gen_img)\n",
        "plot_2(save_folder, gen_img)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE_2wcp3TgKE"
      },
      "source": [
        "#### Style weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR6A6GWddvrO"
      },
      "outputs": [],
      "source": [
        "save_folder = \"res_1_exp_3_\"\n",
        "gen_img, history = train(epoch=100,\n",
        "                        lr=0.05,\n",
        "                        content_weight=5,\n",
        "                        style_weight=10)\n",
        "\n",
        "plot_1(save_folder, gen_img)\n",
        "plot_2(save_folder, gen_img)\n",
        "plot_3(save_folder, history)\n",
        "\n",
        "gen_img, history = train(epoch=100,\n",
        "                        lr=0.05,\n",
        "                        content_weight=5,\n",
        "                        style_weight=1000)\n",
        "\n",
        "plot_1(save_folder, gen_img)\n",
        "plot_2(save_folder, gen_img)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBW_5FRJToWt"
      },
      "source": [
        "### Rotation about both principal axes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7XstE_QBuCuW"
      },
      "outputs": [],
      "source": [
        "idx = [(0, i) for i in range(360)] + [(i, 0) for i in range(360)]\n",
        "\n",
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "save_folder = \"res_1_batch_1_\"\n",
        "\n",
        "lr=0.05\n",
        "content_weight=5\n",
        "style_weight=100\n",
        "\n",
        "model=VGG().to(device).eval() \n",
        "optimizer=optim.Adam([generated_image], lr=lr)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[120, 240], gamma=0.1)\n",
        "history = []\n",
        "print('Optimizing..')\n",
        "for e in range(len(idx)):\n",
        "    optimizer.zero_grad()\n",
        "    elev, azim = idx[e]\n",
        "    R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "    cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "    texture = TexturesUV(maps=generated_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "    mesh = Meshes(\n",
        "        verts=[verts.to(device)],   \n",
        "        faces=faces, \n",
        "        textures=texture\n",
        "    )\n",
        "    images = renderer(mesh, cameras=cameras)[..., :3].permute(0, 3, 1, 2)\n",
        "    \n",
        "    \n",
        "    total_loss=calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "    \n",
        "    total_loss.backward()\n",
        "    history.append(total_loss.detach().cpu().numpy())\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    \n",
        "    #print the image and save it after each 100 epoch\n",
        "    if(not (e%10)):\n",
        "        print(\"Iteration\", e)\n",
        "        print(\"Total Loss:\", total_loss.item())\n",
        "        save_image(generated_image,\"gen.png\")\n",
        "        if len(history) > 1:\n",
        "            plt.plot(np.array(history))\n",
        "            plt.show()\n",
        "        with no_grad():\n",
        "                plt.figure(figsize=(5, 8))\n",
        "                plt.imshow(images.permute(0, 2, 3, 1)[0].cpu().numpy()[..., :3])\n",
        "                plt.show()\n",
        "        img = mpimg.imread('gen.png')\n",
        "        imgplot = plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hMgKzE-xuLdp"
      },
      "outputs": [],
      "source": [
        "plot_1(save_folder, generated_image)\n",
        "plot_2(save_folder, generated_image)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abBhwIIeDu3W"
      },
      "source": [
        "## Experiment № 2 - SGD method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKEbyZw8Dtx2"
      },
      "outputs": [],
      "source": [
        "def gaussian_pyramid_features(model, img, levels, type='none'):    \n",
        "    pyramid_features = []\n",
        "    sizes = [512, 256, 128]\n",
        "    if type == 'generate':\n",
        "        for i in range(levels):\n",
        "            texture = TexturesUV(maps=img.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "            mesh = Meshes(\n",
        "                verts=[verts.to(device)],   \n",
        "                faces=faces, \n",
        "                textures=texture\n",
        "            )\n",
        "            img_size = sizes[i]\n",
        "            rendered_img = renderer(mesh, raster_settings=RasterizationSettings(image_size=img_size, blur_radius=0.0))\n",
        "            target_feature = model(rendered_img[..., :3].permute(0, 3, 1, 2))\n",
        "            pyramid_features.append(target_feature)\n",
        "            img = transforms.Compose([transforms.Resize(img_size)])(img)\n",
        "    else:\n",
        "        for i in range(levels):\n",
        "            img = transforms.Compose([transforms.Resize(sizes[i])])(img)\n",
        "            target_feature = model(img)\n",
        "            pyramid_features.append(target_feature)\n",
        "    return pyramid_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsPz0tzSDt3k"
      },
      "outputs": [],
      "source": [
        "def calculate_loss(model, gen_img, orig_img, style_img, content_weight, style_weight):\n",
        "    content_pyramid_features = gaussian_pyramid_features(model, orig_img, 3)\n",
        "    style_pyramid_features = gaussian_pyramid_features(model, style_img, 3)\n",
        "\n",
        "    gen_pyramid_features = gaussian_pyramid_features(model, gen_img, 3, type='generate')\n",
        "    # print([x.shape for x in content_pyramid_features])\n",
        "    # print([x.shape for x in style_pyramid_features])\n",
        "    # print([x.shape for x in gen_pyramid_features])\n",
        "    style_loss=0\n",
        "    content_loss=0\n",
        "    for gen_f, cont_f, style_f in zip(gen_pyramid_features, content_pyramid_features, style_pyramid_features):\n",
        "        for gen, cont, style in zip(gen_f, cont_f, style_f):\n",
        "            content_loss += calc_content_loss(gen, cont)\n",
        "            style_loss += calc_style_loss(gen, style)\n",
        "    \n",
        "    total_loss = content_weight * content_loss + style_weight * style_loss \n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vCgHNW9O8Kb"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### A fixed camera position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVArkqyODt9t"
      },
      "outputs": [],
      "source": [
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "save_folder = \"res_2_one_cam_\"\n",
        "\n",
        "epoch=300\n",
        "lr=0.01\n",
        "content_weight=70\n",
        "style_weight=0.0001\n",
        "\n",
        "model=VGG().to(device).eval() \n",
        "optimizer=optim.SGD([generated_image], lr=lr)\n",
        "\n",
        "history = []\n",
        "print('Optimizing..')\n",
        "for e in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total_loss=calculate_loss(model, generated_image, original_image, style_image, content_weight, style_weight)\n",
        "    \n",
        "    total_loss.backward()\n",
        "    history.append(total_loss.detach().cpu().numpy())\n",
        "    optimizer.step()\n",
        "    \n",
        "    #print the image and save it after each 100 epoch\n",
        "    if(not (e%30)):\n",
        "        print(\"Iteration\", e)\n",
        "        print(\"Total Loss:\", total_loss.item())\n",
        "        save_image(generated_image,\"gen.png\")\n",
        "        if len(history) > 1:\n",
        "            plt.plot(np.array(history))\n",
        "            plt.show()\n",
        "        img = mpimg.imread('gen.png')\n",
        "        imgplot = plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNJT5uBsDt_z"
      },
      "outputs": [],
      "source": [
        "plot_1(save_folder, generated_image)\n",
        "plot_2(save_folder, generated_image)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3yVsbNqLAZx"
      },
      "source": [
        "### Rotation about a single principal axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqQoQ_YGDuCJ"
      },
      "outputs": [],
      "source": [
        "def gaussian_pyramid_features(model, img, levels, type='none', cameras=None):    \n",
        "    pyramid_features = []\n",
        "    sizes = [784, 608, 432, 256]\n",
        "    if type == 'generate':\n",
        "        for i in range(levels):\n",
        "            texture = TexturesUV(maps=img.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "            mesh = Meshes(\n",
        "                verts=[verts.to(device)],   \n",
        "                faces=faces, \n",
        "                textures=texture\n",
        "            )\n",
        "            img_size = sizes[i]\n",
        "            rendered_img = renderer(mesh, cameras=cameras, raster_settings=RasterizationSettings(image_size=img_size, blur_radius=0.0))\n",
        "            target_feature = model(rendered_img[..., :3].permute(0, 3, 1, 2))\n",
        "            pyramid_features.append(target_feature)\n",
        "            img = transforms.Compose([transforms.Resize(img_size)])(img)\n",
        "    else:\n",
        "        for i in range(levels):\n",
        "            img = transforms.Compose([transforms.Resize(sizes[i])])(img)\n",
        "            target_feature = model(img)\n",
        "            pyramid_features.append(target_feature)\n",
        "    return pyramid_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0ubksrrLB3N"
      },
      "outputs": [],
      "source": [
        "def calculate_loss(model, gen_img, cameras, orig_img, style_img, content_weight, style_weight):\n",
        "    content_pyramid_features = gaussian_pyramid_features(model, orig_img, 4)\n",
        "    style_pyramid_features = gaussian_pyramid_features(model, style_img, 4)\n",
        "\n",
        "    gen_pyramid_features = gaussian_pyramid_features(model, gen_img, 4, type='generate', cameras=cameras)\n",
        "    # print([x.shape for x in content_pyramid_features])\n",
        "    # print([x.shape for x in style_pyramid_features])\n",
        "    # print([x.shape for x in gen_pyramid_features])\n",
        "    style_loss=0\n",
        "    content_loss=0\n",
        "    for gen_f, cont_f, style_f in zip(gen_pyramid_features, content_pyramid_features, style_pyramid_features):\n",
        "        for gen, cont, style in zip(gen_f, cont_f, style_f):\n",
        "            #extracting the dimensions from the generated image\n",
        "            content_loss += calc_content_loss(gen, cont)\n",
        "            style_loss += calc_style_loss(gen, style)\n",
        "    \n",
        "    #calculating the total loss of e th epoch\n",
        "    total_loss = content_weight * content_loss + style_weight * style_loss \n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaHhqn04LB6P"
      },
      "outputs": [],
      "source": [
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "save_folder = \"res_2_seq_cam_\"\n",
        "\n",
        "epoch=100\n",
        "lr=0.01\n",
        "content_weight=70\n",
        "style_weight=0.0001\n",
        "azims = torch.linspace(0, 360, epoch)\n",
        "\n",
        "model=VGG().to(device).eval() \n",
        "optimizer=optim.SGD([generated_image], lr=lr)\n",
        "\n",
        "history = []\n",
        "print('Optimizing..')\n",
        "for e in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    elev = 0\n",
        "    azim = azims[e]\n",
        "    R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "    cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "    texture = TexturesUV(maps=generated_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "    mesh = Meshes(\n",
        "        verts=[verts.to(device)],   \n",
        "        faces=faces, \n",
        "        textures=texture\n",
        "    )\n",
        "    images = renderer(mesh, cameras=cameras)[..., :3].permute(0, 3, 1, 2)\n",
        "    \n",
        "    \n",
        "    total_loss=calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "    \n",
        "    total_loss.backward()\n",
        "    history.append(total_loss.detach().cpu().numpy())\n",
        "    optimizer.step()\n",
        "    \n",
        "    #print the image and save it after each 100 epoch\n",
        "    if(not (e%30)):\n",
        "        print(\"Iteration\", e)\n",
        "        print(\"Total Loss:\", total_loss.item())\n",
        "        save_image(generated_image,\"gen.png\")\n",
        "        if len(history) > 1:\n",
        "            plt.plot(np.array(history))\n",
        "            plt.show()\n",
        "        with no_grad():\n",
        "                plt.figure(figsize=(5, 8))\n",
        "                plt.imshow(images.permute(0, 2, 3, 1)[0].cpu().numpy()[..., :3])\n",
        "                plt.show()\n",
        "        img = mpimg.imread('gen.png')\n",
        "        imgplot = plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcIIlx8GLB9t"
      },
      "outputs": [],
      "source": [
        "plot_1(save_folder, generated_image)\n",
        "plot_2(save_folder, generated_image)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZwg95lSLUF1"
      },
      "source": [
        "### Rotation about both principal axes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltWcWjlZLCGD"
      },
      "outputs": [],
      "source": [
        "idx = [(0, i) for i in range(360)] + [(i, 0) for i in range(360)]\n",
        "\n",
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "save_folder = \"res_2_batch_1_\"\n",
        "\n",
        "lr=0.01\n",
        "content_weight=70\n",
        "style_weight=0.0001\n",
        "\n",
        "model=VGG().to(device).eval() \n",
        "optimizer=optim.SGD([generated_image], lr=lr)\n",
        "\n",
        "history = []\n",
        "print('Optimizing..')\n",
        "for e in range(len(idx)):\n",
        "    optimizer.zero_grad()\n",
        "    elev, azim = idx[e]\n",
        "    R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "    cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "    texture = TexturesUV(maps=generated_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "    mesh = Meshes(\n",
        "        verts=[verts.to(device)],   \n",
        "        faces=faces, \n",
        "        textures=texture\n",
        "    )\n",
        "    images = renderer(mesh, cameras=cameras)[..., :3].permute(0, 3, 1, 2)\n",
        "    \n",
        "    \n",
        "    total_loss=calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "    \n",
        "    total_loss.backward()\n",
        "    history.append(total_loss.detach().cpu().numpy())\n",
        "    optimizer.step()\n",
        "    \n",
        "    #print the image and save it after each 100 epoch\n",
        "    if(not (e%30)):\n",
        "        print(\"Iteration\", e)\n",
        "        print(\"Total Loss:\", total_loss.item())\n",
        "        save_image(generated_image,\"gen.png\")\n",
        "        if len(history) > 1:\n",
        "            plt.plot(np.array(history))\n",
        "            plt.show()\n",
        "        with no_grad():\n",
        "                plt.figure(figsize=(5, 8))\n",
        "                plt.imshow(images.permute(0, 2, 3, 1)[0].cpu().numpy()[..., :3])\n",
        "                plt.show()\n",
        "        img = mpimg.imread('gen.png')\n",
        "        imgplot = plt.imshow(img)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAG0krvULCIn"
      },
      "outputs": [],
      "source": [
        "plot_1(save_folder, generated_image)\n",
        "plot_2(save_folder, generated_image)\n",
        "plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bthOx2BgPvyc"
      },
      "source": [
        "### Evidence SGD has no impact on past pixel gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV5Khb-CPU6B"
      },
      "outputs": [],
      "source": [
        "#generated_image=original_image.clone().requires_grad_(True)\n",
        "original_image = texture_image.permute(0, 3, 1, 2).to(device, torch.float)\n",
        "style_image=image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "save_folder = \"res_2_sgd_\"\n",
        "lr=0.01\n",
        "content_weight=70\n",
        "style_weight=0.0001\n",
        "\n",
        "model=VGG().to(device).eval() \n",
        "optimizer=optim.SGD([generated_image], lr=lr)\n",
        "\n",
        "history = []\n",
        "\n",
        "epoch = 5\n",
        "diff = None\n",
        "first = None\n",
        "image_1 = None\n",
        "azims = torch.linspace(0, 360, epoch)\n",
        "\n",
        "history = []\n",
        "print('Optimizing..')\n",
        "for e in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    elev = 0\n",
        "    azim = azims[e]\n",
        "    R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "    cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "    texture = TexturesUV(maps=generated_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "    mesh = Meshes(\n",
        "        verts=[verts.to(device)],   \n",
        "        faces=faces, \n",
        "        textures=texture\n",
        "    )\n",
        "    images = renderer(mesh, cameras=cameras)[..., :3].permute(0, 3, 1, 2)\n",
        "    \n",
        "    \n",
        "    total_loss=calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "    total_loss.backward()\n",
        "    \n",
        "    # print(torch.sum(generated_image.grad.data != 0))\n",
        "    if first is None:\n",
        "      first = (generated_image.grad != 0).detach().long()\n",
        "      image_1 = generated_image.clone().detach()\n",
        "    else:\n",
        "      gen_2 = (generated_image.grad != 0).detach().long()\n",
        "      second = generated_image.clone().detach()\n",
        "      with no_grad():\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.imshow(image_1.cpu()[0].permute(1, 2, 0).numpy())\n",
        "        plt.savefig(save_path + save_folder + f\"graph_tex_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "        svg_idx += 1\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.imshow(second.cpu()[0].permute(1, 2, 0).numpy())\n",
        "        plt.show()\n",
        "        \n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.imshow(((second - image_1)*50).cpu()[0].permute(1, 2, 0).numpy())\n",
        "        plt.savefig(save_path + save_folder + f\"graph_grad_{svg_idx}.svg\", format='svg', bbox_inches='tight')\n",
        "        svg_idx += 1\n",
        "        plt.show()\n",
        "        \n",
        "        image_1 = second.clone()\n",
        "\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.imshow(images.permute(0, 2, 3, 1)[0].cpu().numpy()[..., :3])\n",
        "        plt.show()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-__goVjsh1t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otlHRn7t1m5m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OXdgO-3L-qM"
      },
      "source": [
        "## Experiment №3 - Comparison of Adam and SGD methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjm5apiSYST_"
      },
      "source": [
        "### SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrYX9o-cWklg"
      },
      "outputs": [],
      "source": [
        "def stylized_sgd(name, style_img, obj_path=\"/content/data/cow_mesh/cow.obj\", \n",
        "             texture=\"/content/data/cow_mesh/cow_texture.png\"):\n",
        "    \n",
        "    verts, faces_idx, aux = load_obj(obj_path)\n",
        "    faces = [faces_idx.verts_idx.to(device)]\n",
        "    if texture:\n",
        "        verts_uvs=[aux.verts_uvs.to(device)]\n",
        "        faces_uvs = [faces_idx.textures_idx.to(device)]\n",
        "\n",
        "    \n",
        "    idx = [(0, i) for i in range(360)] + [(i, 0) for i in range(30, 90)] + [(i, 0) for i in range(30, 90)] + [(i, 0) for i in range(250, 310)] + [(i, 0) for i in range(250, 310)] \n",
        "    if texture is None:\n",
        "        texture = transforms.ToPILImage(torch.rand(3, 1024, 1024))\n",
        "        original_image = image_loader(texture).to(device, torch.float)\n",
        "    else:\n",
        "        original_image = image_loader(Image.open(texture)).to(device, torch.float)\n",
        "    \n",
        "    style_image= style_img\n",
        "    generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "    save_folder = \"train_sgd_\" + name + \"_\"\n",
        "\n",
        "    lr=0.01\n",
        "    content_weight=70\n",
        "    style_weight=0.0001\n",
        "\n",
        "    model=VGG().to(device).eval() \n",
        "    optimizer=optim.SGD([generated_image], lr=lr)\n",
        "\n",
        "    history = []\n",
        "    print('Optimizing..')\n",
        "    epoch = len(idx)\n",
        "    for e in range(epoch):\n",
        "        optimizer.zero_grad()\n",
        "        elev, azim = idx[e]\n",
        "        R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "        cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "        texture = TexturesUV(maps=generated_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "        mesh = Meshes(\n",
        "            verts=[verts.to(device)],   \n",
        "            faces=faces, \n",
        "            textures=texture\n",
        "        )\n",
        "        images = renderer(mesh, cameras=cameras)[..., :3].permute(0, 3, 1, 2)\n",
        "        \n",
        "        \n",
        "        total_loss=calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "        \n",
        "        total_loss.backward()\n",
        "        history.append(total_loss.detach().cpu().numpy())\n",
        "        optimizer.step()\n",
        "        \n",
        "        #print the image and save it after each 100 epoch\n",
        "        \n",
        "        if(not (e%30)):\n",
        "            print(\"Iteration\", e)\n",
        "            print(\"Total Loss:\", total_loss.item())\n",
        "            save_image(generated_image,\"gen.png\")\n",
        "            if len(history) > 1:\n",
        "                plt.plot(np.array(history))\n",
        "                plt.show()\n",
        "            with no_grad():\n",
        "                    plt.figure(figsize=(5, 8))\n",
        "                    plt.imshow(images.permute(0, 2, 3, 1)[0].cpu().numpy()[..., :3])\n",
        "                    plt.show()\n",
        "            img = mpimg.imread('gen.png')\n",
        "            imgplot = plt.imshow(img)\n",
        "            plt.show()\n",
        "    \n",
        "    plot_1(save_folder, generated_image)\n",
        "    plot_2(save_folder, generated_image)\n",
        "    plot_3(save_folder, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOWfVp5tXYeX"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "stylized_sgd(name=\"Starry_Night\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1s62yNsaXYmf"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Claude-Monet-1.jpg'))\n",
        "stylized_sgd(name=\"Claude-Monet-1\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rfbgd8B3XYp5"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Kandinsky-Composition-II.jpg'))\n",
        "stylized_sgd(name=\"Kandinsky\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7032GMX6YKkR"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Monet_-_Impression_Sunrise.jpg'))\n",
        "stylized_sgd(name=\"Sunrise\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZD9UsmlDhhI"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Kiss.jpg'))\n",
        "stylized_sgd(name=\"Kiss\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtom7FhX_uU_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrMNkFfZt5-H"
      },
      "source": [
        "### Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yHnzVKkXsiX"
      },
      "outputs": [],
      "source": [
        "def stylized_adam(name, style_img, obj_path=\"/content/data/cow_mesh/cow.obj\", \n",
        "             texture=\"/content/data/cow_mesh/cow_texture.png\"):\n",
        "    \n",
        "    verts, faces_idx, aux = load_obj(obj_path)\n",
        "    verts_uvs=[aux.verts_uvs.to(device)]\n",
        "    faces = [faces_idx.verts_idx.to(device)]\n",
        "    faces_uvs = [faces_idx.textures_idx.to(device)]\n",
        "\n",
        "    m = 10\n",
        "    idx = [(0, i*(360/m)) for i in range(m)] + [(30, 0), (60, 0), (90, 0), (250, 0), (280, 0), (310, 0)] \n",
        "\n",
        "    if texture is None:\n",
        "        texture = transforms.ToPILImage(torch.rand(3, 1024, 1024))\n",
        "        original_image = image_loader(texture).to(device, torch.float)\n",
        "    else:\n",
        "        original_image = image_loader(Image.open(texture)).to(device, torch.float)\n",
        "    \n",
        "    style_image= style_img\n",
        "    generated_image=Variable(original_image.clone().detach(), requires_grad=True).to(device)\n",
        "    save_folder = \"train_adam_\" + name + \"_\"\n",
        "\n",
        "    lr=0.1\n",
        "    content_weight=5\n",
        "    style_weight=100\n",
        "\n",
        "    model=VGG().to(device).eval() \n",
        "    optimizer=optim.Adam([generated_image], lr=lr)\n",
        "\n",
        "    history = []\n",
        "    print('Optimizing..')\n",
        "    epoch = len(idx)\n",
        "    for e in range(epoch):\n",
        "        elev, azim = idx[e]\n",
        "        \n",
        "        for k in range(20):\n",
        "            optimizer.zero_grad()\n",
        "            R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
        "            cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "            texture = TexturesUV(maps=generated_image.permute(0, 2, 3, 1), faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
        "\n",
        "            mesh = Meshes(\n",
        "                verts=[verts.to(device)],   \n",
        "                faces=faces, \n",
        "                textures=texture\n",
        "            )\n",
        "            images = renderer(mesh, cameras=cameras)[..., :3].permute(0, 3, 1, 2)\n",
        "            \n",
        "            \n",
        "            total_loss=calculate_loss(model, generated_image, cameras, original_image, style_image, content_weight, style_weight)\n",
        "            total_loss.backward()\n",
        "            history.append(total_loss.detach().cpu().numpy())\n",
        "            optimizer.step()\n",
        "        \n",
        "        #print the image and save it after each 100 epoch\n",
        "            if(not (k%10)):\n",
        "                print(\"Iteration\", e)\n",
        "                print(\"k is\", k)\n",
        "                print(\"Total Loss:\", total_loss.item())\n",
        "                save_image(generated_image,\"gen.png\")\n",
        "                if len(history) > 1:\n",
        "                    plt.plot(np.array(history))\n",
        "                    plt.show()\n",
        "                with no_grad():\n",
        "                        plt.figure(figsize=(5, 8))\n",
        "                        plt.imshow(images.permute(0, 2, 3, 1)[0].cpu().numpy()[..., :3])\n",
        "                        plt.show()\n",
        "                img = mpimg.imread('gen.png')\n",
        "                imgplot = plt.imshow(img)\n",
        "                plt.show()\n",
        "\n",
        "    plot_1(save_folder, generated_image)\n",
        "    plot_2(save_folder, generated_image)\n",
        "    plot_3(save_folder, history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edCiJzTpY6uo"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Starry_Night.jpg'))\n",
        "stylized_adam(name=\"Starry_Night\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guo_GxAUYzo4"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Claude-Monet-1.jpg'))\n",
        "stylized_adam(name=\"Claude-Monet-1\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGQyuEUyYzvf"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Kandinsky-Composition-II.jpg'))\n",
        "stylized_adam(name=\"Kandinsky\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN9YFvPNYz2T"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Monet_-_Impression_Sunrise.jpg'))\n",
        "stylized_adam(name=\"Sunrise\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjIy0QmZcLX0"
      },
      "outputs": [],
      "source": [
        "style_image = image_loader(Image.open('/content/Kiss.jpg'))\n",
        "stylized_adam(name=\"Kiss\", style_img=style_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2tqWz73jhmK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 1340.228464,
      "end_time": "2020-11-16T14:19:39.956875",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-11-16T13:57:19.728411",
      "version": "2.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
